# DWML_MLLWSE_Code
Source code and reproduction materials for DWML-EFS and MLLWSE â€” feature selection and stacked ensemble learning methods.
This repository provides the **full implementation** of two proposed multi-label learning methods:  

1. **Dynamic Weighted Multi-Label Ensemble Feature Selection (DWML-EFS)** â€” integrates information-theoretic approaches to reduce computational costs while improving feature selection efficiency.  
2. **Multi-Label Linearly Weighted Stacked Ensemble (MLLWSE)** â€” enhances predictive performance via a linearly weighted stacking strategy across multiple base learners.  

Each method includes a **Jupyter Notebook** for step-by-step reproduction of the experimental results reported in our paper.

---

## ðŸ“¦ Requirements
- Python 3.8+  
- `scikit-learn`  
- `scikit-multilearn`  
- `numpy`  
- `scipy`  
- `pandas`  

---

## ðŸ“‚ Repository Structure
```
DWML-EFS/  
â”‚   classes/                 # Supporting modules for DWML-EFS
â”‚   results/                 # Output results from experiments
â”‚   data.py                  # Data handling utilities
â”‚   Demo_CHD_BR_RF.ipynb     # Demonstration with CHD dataset
â”‚   evaluation.py            # General evaluation functions
â”‚   evaluationARAM.py        # Evaluation with ARAM model
â”‚   evaluationKNN.py         # Evaluation with KNN model
â”‚   FinalCode.ipynb          # Main reproduction notebook
â”‚   mlmetrics.py             # Multi-label evaluation metrics
â”‚   mlsmote.py               # SMOTE variant for multi-label data

MLLWSE/  
â”‚   Demo_MLLWSEStacking.ipynb  # Main reproduction notebook
â”‚   lasso.py                   # LASSO optimization
â”‚   mlmetrics.py               # Multi-label evaluation metrics
â”‚   read_matfile.py            # Load .mat datasets
â”‚   utils.py                   # Utility functions
```

---

## ðŸ“¥ Dataset Preparation
Some example datasets are included in `DWML-EFS/results/` and `MLLWSE/`.  
Additional datasets can be downloaded from:  
- [Mulan](http://mulan.sourceforge.net/datasets.html)  
- [KDIS](http://www.uco.es/kdis/mllresources/)  
- [Meka](http://meka.sourceforge.net/)  

**Supported formats:**  
- `.arff` â€” load using `read_arff.py` (if available)  
- `.mat` â€” load using:
```bash
python MLLWSE/read_matfile.py
```

---

## ðŸš€ Running the Code

### 1. DWML-EFS

Run the demonstration notebook:
```bash
jupyter notebook Demo_CHD_BR_RF.ipynb
```

### 2. MLLWSE
Run the main reproduction notebook:
```bash
cd MLLWSE
jupyter notebook Demo_MLLWSEStacking.ipynb
```

---

## ðŸ“Š Evaluation Metrics
Implemented in `mlmetrics.py` (both folders):  
- Hamming Loss  
- Accuracy  
- Ranking Loss  
- F1-score  
- Macro-F1  
- Micro-F1  

---

## ðŸ“ˆ Additional Analyses
Some scripts also include:
- **Parameter sensitivity experiments**  
- **Convergence analysis**  
- **Statistical significance tests** (e.g., Friedman test)

---
